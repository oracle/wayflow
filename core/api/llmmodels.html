


<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>LLMs &#8212; wayflowcore 26.1.0.dev0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dba54f56160742ef5599" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dba54f56160742ef5599" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.4cbf315f70debaebd550c87a6162cf0f.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css-style.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/core.css" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=dba54f56160742ef5599"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dba54f56160742ef5599" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dba54f56160742ef5599" />

  
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/design-tabs.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'core/api/llmmodels';</script>
  <script src="../../_static/announcement.js"></script>

    <link rel="icon" href="../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Events" href="events.html" />
    <link rel="prev" title="Conversations" href="conversation.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="26.1" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo-light.svg" class="logo__image only-light" alt="wayflowcore 26.1.0.dev0 documentation - Home"/>
    <img src="../../_static/logo-dark.svg" class="logo__image only-dark pst-js-only" alt="wayflowcore 26.1.0.dev0 documentation - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Essentials</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorials/index.html">Tutorials &amp; Use Cases</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/basic_agent.html">Build a Simple Conversational Assistant with Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/basic_flow.html">Build a Simple Fixed-flow Assistant with Flows</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/usecase_prbot.html">Build a Simple Code Review Assistant</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../howtoguides/index.html">How-to Guides</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/io_descriptors.html">Change Input and Output Descriptors of Components</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_async.html">Use Asynchronous APIs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/agents.html">Create a ReAct Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_imagecontent.html">How to Send Images to LLMs and Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_ociagent.html">Use OCI Generative AI Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_prompttemplate.html">Use Templates for Advanced Prompting Techniques</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_userinputinflows.html">Ask for User Input in Flows</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/conditional_flows.html">Create Conditional Transitions in Flows</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/promptexecutionstep.html">Do Structured LLM Generation in Flows</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_userconfirmation.html">Add User Confirmation to a Tool Call Request</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/catching_exceptions.html">Catch Exceptions in Flows</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_mapstep.html">Do Map and Reduce Operations in Flows</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_agents_in_flows.html">Use Agents in Flows</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_multiagent.html">Build a Hierarchical Multi-Agent System</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_swarm.html">Build a Swarm of Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_managerworkers.html">Build a ManagerWorkers of Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_build_assistants_with_tools.html">Build Assistants with Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_multiple_output_tool.html">Create Tools with Multiple Outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/create_a_tool_from_a_flow.html">Convert Flows to Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_mcp.html">Connect MCP tools to Assistants</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_remote_tool_expired_token.html">Do Remote API Calls with Tokens</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_execute_agentspec_with_wayflowcore.html">Load and Execute an Agent Spec Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_serdeser.html">Serialize and Deserialize Flows and Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_serialize_conversations.html">Serialize and Deserialize Conversations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/generation_config.html">Specify the Generation Configuration when Using LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/llm_from_different_providers.html">Use LLM from Different LLM Sources and Providers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/installing_ollama.html">Install and Use Ollama</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_tracing.html">Enable Tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_datastores.html">Connect Assistants to Your Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/embeddingmodels_from_different_providers.html">Use Embedding Models from Different Providers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_evaluation.html">How to Evaluate WayFlow Assistants</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_conversation_evaluation.html">How to Evaluate Assistant Conversations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../howtoguides/howto_variable.html">Use Variables for Shared State in Flows</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">API Reference</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="agentspec.html">Agent Spec Adapters</a></li>

<li class="toctree-l2"><a class="reference internal" href="conversation.html">Conversations</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="events.html">Events</a></li>
<li class="toctree-l2"><a class="reference internal" href="flows.html">Flows</a></li>
<li class="toctree-l2"><a class="reference internal" href="agent.html">Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="embeddingmodels.html">Embedding Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="contextproviders.html">Context Providers</a></li>
<li class="toctree-l2"><a class="reference internal" href="interrupts.html">Execution Interrupts</a></li>
<li class="toctree-l2"><a class="reference internal" href="prompttemplate.html">PromptTemplates</a></li>
<li class="toctree-l2"><a class="reference internal" href="serialization.html">Serialization/Deserialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="tools.html">Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="tracing.html">Tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="variables.html">Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="datastores.html">Datastores</a></li>
<li class="toctree-l2"><a class="reference internal" href="warnings.html">Warnings</a></li>
<li class="toctree-l2"><a class="reference internal" href="evaluation.html">Evaluation</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../misc/reference_sheet.html">Reference Sheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../misc/glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../security.html">Security Considerations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">For Contributors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faqs.html">Frequently Asked Questions</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">WayFlow</a></li>
    
    
    <li class="breadcrumb-item"><a href="index.html" class="nav-link">API Reference</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">LLMs</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="llms">
<h1>LLMs<a class="headerlink" href="#llms" title="Permalink to this heading">#</a></h1>
<p>This page presents all APIs and classes related to LLM models.</p>
<div class="sd-container-fluid sd-sphinx-override sd-mb-4 docutils">
<div class="sd-row sd-row-cols-1 sd-row-cols-xs-1 sd-row-cols-sm-1 sd-row-cols-md-1 sd-row-cols-lg-1 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm sd-card-hover docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<a class="reference internal" href="../../_images/agentspec-icon.svg"><img alt="agentspec-icon" src="../../_images/agentspec-icon.svg" width="100px" /></a></div>
<p class="sd-card-text">Visit the Agent Spec API Documentation to learn more about LLMs Components.</p>
</div>
<a class="sd-stretched-link sd-hide-link-text reference external" href="https://oracle.github.io/agent-spec/api/llmmodels.html"><span>Agent Spec - LLMs API Reference</span></a></div>
</div>
</div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Click the button above ↑ to visit the <a class="reference external" href="https://oracle.github.io/agent-spec/index.html">Agent Spec Documentation</a></p>
</div>
<section id="llmmodel">
<h2>LlmModel<a class="headerlink" href="#llmmodel" title="Permalink to this heading">#</a></h2>
<span class="target" id="id1"></span><dl class="py class">
<dt class="sig sig-object py" id="wayflowcore.models.llmmodel.LlmModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wayflowcore.models.llmmodel.</span></span><span class="sig-name descname"><span class="pre">LlmModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generation_config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chat_template</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">agent_template</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">supports_structured_generation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">supports_tool_calling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">__metadata_info__</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">description</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.llmmodel.LlmModel" title="Permalink to this definition">#</a></dt>
<dd><p>Base class for LLM models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_id</strong> (<em>str</em>) – ID of the model.</p></li>
<li><p><strong>generation_config</strong> (<a class="reference internal" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig" title="wayflowcore.models.llmgenerationconfig.LlmGenerationConfig"><em>LlmGenerationConfig</em></a><em> | </em><em>None</em>) – Parameters for LLM generation.</p></li>
<li><p><strong>chat_template</strong> (<a class="reference internal" href="prompttemplate.html#wayflowcore.templates.template.PromptTemplate" title="wayflowcore.templates.template.PromptTemplate"><em>PromptTemplate</em></a><em> | </em><em>None</em>) – Default template for chat completion.</p></li>
<li><p><strong>agent_template</strong> (<a class="reference internal" href="prompttemplate.html#wayflowcore.templates.template.PromptTemplate" title="wayflowcore.templates.template.PromptTemplate"><em>PromptTemplate</em></a><em> | </em><em>None</em>) – Default template for agents using this model.</p></li>
<li><p><strong>supports_structured_generation</strong> (<em>bool</em><em> | </em><em>None</em>) – Whether the model supports structured generation or not. When set to <cite>None</cite>,
the model will be prompted with a response format and it will check it can use
structured generation.</p></li>
<li><p><strong>supports_tool_calling</strong> (<em>bool</em><em> | </em><em>None</em>) – Whether the model supports tool calling or not. When set to <cite>None</cite>,
the model will be prompted with a tool and it will check it can use
the tool.</p></li>
<li><p><strong>id</strong> (<em>str</em><em> | </em><em>None</em>) – ID of the component.</p></li>
<li><p><strong>name</strong> (<em>str</em><em> | </em><em>None</em>) – Name of the component.</p></li>
<li><p><strong>description</strong> (<em>str</em><em> | </em><em>None</em>) – Description of the component.</p></li>
<li><p><strong>__metadata_info__</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="wayflowcore.models.llmmodel.LlmModel.config">
<em class="property"><span class="pre">abstract</span><span class="w"> </span><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">config</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#wayflowcore.models.llmmodel.LlmModel.config" title="Permalink to this definition">#</a></dt>
<dd><p>Get the configuration dictionary for the {VLlm/OpenAI/…} model</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="wayflowcore.models.llmmodel.LlmModel.default_agent_template">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">default_agent_template</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="prompttemplate.html#wayflowcore.templates.template.PromptTemplate" title="wayflowcore.templates.template.PromptTemplate"><span class="pre">PromptTemplate</span></a></em><a class="headerlink" href="#wayflowcore.models.llmmodel.LlmModel.default_agent_template" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="wayflowcore.models.llmmodel.LlmModel.default_chat_template">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">default_chat_template</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="prompttemplate.html#wayflowcore.templates.template.PromptTemplate" title="wayflowcore.templates.template.PromptTemplate"><span class="pre">PromptTemplate</span></a></em><a class="headerlink" href="#wayflowcore.models.llmmodel.LlmModel.default_chat_template" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="wayflowcore.models.llmmodel.LlmModel.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_conversation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.llmmodel.LlmModel.generate" title="Permalink to this definition">#</a></dt>
<dd><p>Generates a new message based on a prompt using a LLM</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em><em> | </em><em>Prompt</em>) – Prompt that contains the messages and other arguments to send to the LLM</p></li>
<li><p><strong>_conversation</strong> (<a class="reference internal" href="conversation.html#wayflowcore.conversation.Conversation" title="wayflowcore.conversation.Conversation"><em>Conversation</em></a><em> | </em><em>None</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>LlmCompletion</em></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">wayflowcore.messagelist</span><span class="w"> </span><span class="kn">import</span> <span class="n">Message</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">wayflowcore.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">Prompt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prompt</span> <span class="o">=</span> <span class="n">Prompt</span><span class="p">(</span><span class="n">messages</span><span class="o">=</span><span class="p">[</span><span class="n">Message</span><span class="p">(</span><span class="s1">&#39;What is the capital of Switzerland?&#39;</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">completion</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># LlmCompletion(message=Message(content=&#39;The capital of Switzerland is Bern&#39;))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="wayflowcore.models.llmmodel.LlmModel.generate_async">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">generate_async</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_conversation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.llmmodel.LlmModel.generate_async" title="Permalink to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em><em> | </em><em>Prompt</em>) – </p></li>
<li><p><strong>_conversation</strong> (<a class="reference internal" href="conversation.html#wayflowcore.conversation.Conversation" title="wayflowcore.conversation.Conversation"><em>Conversation</em></a><em> | </em><em>None</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>LlmCompletion</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="wayflowcore.models.llmmodel.LlmModel.get_total_token_consumption">
<span class="sig-name descname"><span class="pre">get_total_token_consumption</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">conversation_id</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.llmmodel.LlmModel.get_total_token_consumption" title="Permalink to this definition">#</a></dt>
<dd><p>Calculate and return the total token consumption for a given conversation.</p>
<p>This method computes the aggregate token usage for the specified conversation
by summing the token usages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>conversation_id</strong> (<em>str</em>) – The unique identifier for the conversation whose token consumption is to be calculated.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A TokenUsage object that gathers all token usage information.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-class docutils literal notranslate"><span class="pre">TokenUsage</span></code></dt><dd><p>An object to gather all token usage information.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="wayflowcore.models.llmmodel.LlmModel.stream_generate">
<span class="sig-name descname"><span class="pre">stream_generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_conversation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.llmmodel.LlmModel.stream_generate" title="Permalink to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em><em> | </em><em>Prompt</em>) – </p></li>
<li><p><strong>_conversation</strong> (<a class="reference internal" href="conversation.html#wayflowcore.conversation.Conversation" title="wayflowcore.conversation.Conversation"><em>Conversation</em></a><em> | </em><em>None</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Iterable</em>[<em>Tuple</em>[<em>StreamChunkType</em>, <a class="reference internal" href="conversation.html#wayflowcore.messagelist.Message" title="wayflowcore.messagelist.Message">Message</a> | None]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="wayflowcore.models.llmmodel.LlmModel.stream_generate_async">
<em class="property"><span class="pre">async</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">stream_generate_async</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_conversation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.llmmodel.LlmModel.stream_generate_async" title="Permalink to this definition">#</a></dt>
<dd><p>Returns an async iterator of message chunks</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prompt</strong> (<em>str</em><em> | </em><em>Prompt</em>) – Prompt that contains the messages and other arguments to send to the LLM</p></li>
<li><p><strong>_conversation</strong> (<a class="reference internal" href="conversation.html#wayflowcore.conversation.Conversation" title="wayflowcore.conversation.Conversation"><em>Conversation</em></a><em> | </em><em>None</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>AsyncIterable</em>[<em>Tuple</em>[<em>StreamChunkType</em>, <a class="reference internal" href="conversation.html#wayflowcore.messagelist.Message" title="wayflowcore.messagelist.Message">Message</a> | None]]</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">asyncio</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">wayflowcore.messagelist</span><span class="w"> </span><span class="kn">import</span> <span class="n">Message</span><span class="p">,</span> <span class="n">MessageType</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">wayflowcore.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">Prompt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">message</span> <span class="o">=</span> <span class="n">Message</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">&quot;What is the capital of Switzerland?&quot;</span><span class="p">,</span> <span class="n">message_type</span><span class="o">=</span><span class="n">MessageType</span><span class="o">.</span><span class="n">USER</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">llm_stream</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">stream_generate</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">prompt</span><span class="o">=</span><span class="n">Prompt</span><span class="p">(</span><span class="n">messages</span><span class="o">=</span><span class="p">[</span><span class="n">message</span><span class="p">])</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">chunk_type</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">llm_stream</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>   
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Bern</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#  is the</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># capital</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#  of</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#  Switzerland</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Message(content=&#39;Bern is the capital of Switzerland&#39;, message_type=MessageType.AGENT)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="llmmodelfactory">
<h2>LlmModelFactory<a class="headerlink" href="#llmmodelfactory" title="Permalink to this heading">#</a></h2>
<span class="target" id="id2"></span><dl class="py class">
<dt class="sig sig-object py" id="wayflowcore.models.llmmodelfactory.LlmModelFactory">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wayflowcore.models.llmmodelfactory.</span></span><span class="sig-name descname"><span class="pre">LlmModelFactory</span></span><a class="headerlink" href="#wayflowcore.models.llmmodelfactory.LlmModelFactory" title="Permalink to this definition">#</a></dt>
<dd><p>Factory class that creates <code class="docutils literal notranslate"><span class="pre">LlmModel</span></code> instances from configuration dictionaries.</p>
<p>Supports vLLM, Ollama, OpenAI and OCIGenAI models.</p>
<dl class="py method">
<dt class="sig sig-object py" id="wayflowcore.models.llmmodelfactory.LlmModelFactory.from_config">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.llmmodelfactory.LlmModelFactory.from_config" title="Permalink to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model_config</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#wayflowcore.models.llmmodel.LlmModel" title="wayflowcore.models.llmmodel.LlmModel"><em>LlmModel</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="token-usage">
<h2>Token Usage<a class="headerlink" href="#token-usage" title="Permalink to this heading">#</a></h2>
<p>Class that is used to gather all token usage information.</p>
<span class="target" id="tokenusage"></span><dl class="py class">
<dt class="sig sig-object py" id="wayflowcore.tokenusage.TokenUsage">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wayflowcore.tokenusage.</span></span><span class="sig-name descname"><span class="pre">TokenUsage</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cached_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exact_count</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.tokenusage.TokenUsage" title="Permalink to this definition">#</a></dt>
<dd><p>Gathers all token usage information.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_tokens</strong> (<em>int</em>) – Number of tokens used as input/context.</p></li>
<li><p><strong>cached_tokens</strong> (<em>int</em>) – Number of tokens in prompt that were cached.</p></li>
<li><p><strong>output_tokens</strong> (<em>int</em>) – Number of tokens generated by the model.</p></li>
<li><p><strong>exact_count</strong> (<em>bool</em>) – Whether these numbers are exact or were estimated using the 1 token ≈ 3/4 word rule</p></li>
<li><p><strong>total_tokens</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="wayflowcore.tokenusage.TokenUsage.cached_tokens">
<span class="sig-name descname"><span class="pre">cached_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#wayflowcore.tokenusage.TokenUsage.cached_tokens" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wayflowcore.tokenusage.TokenUsage.exact_count">
<span class="sig-name descname"><span class="pre">exact_count</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#wayflowcore.tokenusage.TokenUsage.exact_count" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wayflowcore.tokenusage.TokenUsage.input_tokens">
<span class="sig-name descname"><span class="pre">input_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#wayflowcore.tokenusage.TokenUsage.input_tokens" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wayflowcore.tokenusage.TokenUsage.output_tokens">
<span class="sig-name descname"><span class="pre">output_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#wayflowcore.tokenusage.TokenUsage.output_tokens" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wayflowcore.tokenusage.TokenUsage.total_tokens">
<span class="sig-name descname"><span class="pre">total_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#wayflowcore.tokenusage.TokenUsage.total_tokens" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="llm-generation-config">
<h2>LLM Generation Config<a class="headerlink" href="#llm-generation-config" title="Permalink to this heading">#</a></h2>
<p>Parameters for LLM generation (<code class="docutils literal notranslate"><span class="pre">max_tokens</span></code>, <code class="docutils literal notranslate"><span class="pre">temperature</span></code>, <code class="docutils literal notranslate"><span class="pre">top_p</span></code>).</p>
<span class="target" id="llmgenerationconfig"></span><dl class="py class">
<dt class="sig sig-object py" id="wayflowcore.models.llmgenerationconfig.LlmGenerationConfig">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wayflowcore.models.llmgenerationconfig.</span></span><span class="sig-name descname"><span class="pre">LlmGenerationConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_tokens=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_p=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frequency_penalty=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extra_args=&lt;factory&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">id=&lt;factory&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">__metadata_info__=&lt;factory&gt;</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig" title="Permalink to this definition">#</a></dt>
<dd><p>Parameters for LLM generation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_tokens</strong> (<em>int</em><em> | </em><em>None</em>) – Maximum number of tokens to generate as output.</p></li>
<li><p><strong>temperature</strong> (<em>float</em><em> | </em><em>None</em>) – What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random,
while lower values like 0.2 will make it more focused and deterministic.
We generally recommend altering this or <code class="docutils literal notranslate"><span class="pre">top_p</span></code> but not both.</p></li>
<li><p><strong>top_p</strong> (<em>float</em><em> | </em><em>None</em>) – An alternative to sampling with temperature, called nucleus sampling, where the model considers the results
of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability
mass are considered.
We generally recommend altering this or temperature but not both.</p></li>
<li><p><strong>stop</strong> (<em>List</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – List of stop words to indicate the LLM to stop generating when encountering one of these words. This helps
reducing hallucinations, when using templates like ReAct. Some reasoning models (o3, o4-mini…) might
not support it.</p></li>
<li><p><strong>frequency_penalty</strong> (<em>float</em><em> | </em><em>None</em>) – float between -2.0 and 2.0 that penalizes new tokens based on their frequency in the generated text so far.
Values &gt; 0 encourage the model to use new tokens, while values &lt; 0 encourage the model to repeat tokens.</p></li>
<li><p><strong>extra_args</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – <p>dictionary of extra arguments that can be used by specific model providers</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The extra parameters should never include sensitive information.</p>
</div>
</p></li>
<li><p><strong>id</strong> (<em>str</em>) – </p></li>
<li><p><strong>__metadata_info__</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.extra_args">
<span class="sig-name descname"><span class="pre">extra_args</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.extra_args" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.frequency_penalty">
<span class="sig-name descname"><span class="pre">frequency_penalty</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.frequency_penalty" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.from_dict">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.from_dict" title="Permalink to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>config</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig" title="wayflowcore.models.llmgenerationconfig.LlmGenerationConfig"><em>LlmGenerationConfig</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.max_tokens">
<span class="sig-name descname"><span class="pre">max_tokens</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.max_tokens" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.merge_config">
<span class="sig-name descname"><span class="pre">merge_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.merge_config" title="Permalink to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>overriding_config</strong> (<a class="reference internal" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig" title="wayflowcore.models.llmgenerationconfig.LlmGenerationConfig"><em>LlmGenerationConfig</em></a><em> | </em><em>None</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig" title="wayflowcore.models.llmgenerationconfig.LlmGenerationConfig"><em>LlmGenerationConfig</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.stop">
<span class="sig-name descname"><span class="pre">stop</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.stop" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.temperature">
<span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.temperature" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.to_dict">
<span class="sig-name descname"><span class="pre">to_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.to_dict" title="Permalink to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Dict</em>[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.top_p">
<span class="sig-name descname"><span class="pre">top_p</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.top_p" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="all-models">
<span id="allllms"></span><h2>All models<a class="headerlink" href="#all-models" title="Permalink to this heading">#</a></h2>
<section id="openai-compatible-models">
<h3>OpenAI Compatible Models<a class="headerlink" href="#openai-compatible-models" title="Permalink to this heading">#</a></h3>
<span class="target" id="openaicompatiblemodel"></span><dl class="py class">
<dt class="sig sig-object py" id="wayflowcore.models.openaicompatiblemodel.OpenAICompatibleModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wayflowcore.models.openaicompatiblemodel.</span></span><span class="sig-name descname"><span class="pre">OpenAICompatibleModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_url</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proxy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generation_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">supports_structured_generation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">supports_tool_calling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">__metadata_info__</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">description</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.openaicompatiblemodel.OpenAICompatibleModel" title="Permalink to this definition">#</a></dt>
<dd><p>Model to use remote LLM endpoints that use OpenAI-compatible chat APIs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_id</strong> (<em>str</em>) – Name of the model to use</p></li>
<li><p><strong>base_url</strong> (<em>str</em>) – Hostname and port of the vllm server where the model is hosted. If you specify a url
ending with <cite>/completions</cite> it will be used as-is, otherwise the url path
<cite>v1/chat/completions</cite> will be appended to the base url.</p></li>
<li><p><strong>proxy</strong> (<em>str</em><em> | </em><em>None</em>) – Proxy to use to connect to the remote LLM endpoint</p></li>
<li><p><strong>api_key</strong> (<em>str</em><em> | </em><em>None</em>) – API key to use for the request if needed. It will be formatted in the OpenAI format
(as “Bearer API_KEY” in the request header)</p></li>
<li><p><strong>generation_config</strong> (<a class="reference internal" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig" title="wayflowcore.models.llmgenerationconfig.LlmGenerationConfig"><em>LlmGenerationConfig</em></a><em> | </em><em>None</em>) – default parameters for text generation with this model</p></li>
<li><p><strong>supports_structured_generation</strong> (<em>bool</em><em> | </em><em>None</em>) – Whether the model supports structured generation or not. When set to <cite>None</cite>,
the model will be prompted with a response format and it will check it can use
structured generation.</p></li>
<li><p><strong>supports_tool_calling</strong> (<em>bool</em><em> | </em><em>None</em>) – Whether the model supports tool calling or not. When set to <cite>None</cite>,
the model will be prompted with a tool and it will check it can use
the tool.</p></li>
<li><p><strong>id</strong> (<em>str</em><em> | </em><em>None</em>) – ID of the component.</p></li>
<li><p><strong>name</strong> (<em>str</em><em> | </em><em>None</em>) – Name of the component.</p></li>
<li><p><strong>description</strong> (<em>str</em><em> | </em><em>None</em>) – Description of the component.</p></li>
<li><p><strong>__metadata_info__</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – </p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">wayflowcore.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAICompatibleModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAICompatibleModel</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;&lt;MODEL_NAME&gt;&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">base_url</span><span class="o">=</span><span class="s2">&quot;&lt;ENDPOINT_URL&gt;&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;&lt;API_KEY_FOR_REMOTE_ENDPOINT&gt;&quot;</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="wayflowcore.models.openaicompatiblemodel.OpenAICompatibleModel.config">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">config</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#wayflowcore.models.openaicompatiblemodel.OpenAICompatibleModel.config" title="Permalink to this definition">#</a></dt>
<dd><p>Get the configuration dictionary for the {VLlm/OpenAI/…} model</p>
</dd></dl>

</dd></dl>

</section>
<section id="openai-models">
<h3>OpenAI Models<a class="headerlink" href="#openai-models" title="Permalink to this heading">#</a></h3>
<span class="target" id="openaimodel"></span><dl class="py class">
<dt class="sig sig-object py" id="wayflowcore.models.openaimodel.OpenAIModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wayflowcore.models.openaimodel.</span></span><span class="sig-name descname"><span class="pre">OpenAIModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gpt-4o-mini'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generation_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proxy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">__metadata_info__</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">description</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.openaimodel.OpenAIModel" title="Permalink to this definition">#</a></dt>
<dd><p>Model powered by OpenAI.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_id</strong> (<em>str</em>) – Name of the model to use</p></li>
<li><p><strong>api_key</strong> (<em>str</em><em> | </em><em>None</em>) – API key for the OpenAI endpoint. Overrides existing <code class="docutils literal notranslate"><span class="pre">OPENAI_API_KEY</span></code> environment variable.</p></li>
<li><p><strong>generation_config</strong> (<a class="reference internal" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig" title="wayflowcore.models.llmgenerationconfig.LlmGenerationConfig"><em>LlmGenerationConfig</em></a><em> | </em><em>None</em>) – default parameters for text generation with this model</p></li>
<li><p><strong>proxy</strong> (<em>str</em><em> | </em><em>None</em>) – proxy to access the remote model under VPN</p></li>
<li><p><strong>id</strong> (<em>str</em><em> | </em><em>None</em>) – ID of the component.</p></li>
<li><p><strong>name</strong> (<em>str</em><em> | </em><em>None</em>) – Name of the component.</p></li>
<li><p><strong>description</strong> (<em>str</em><em> | </em><em>None</em>) – Description of the component.</p></li>
<li><p><strong>important::</strong> (<em>..</em>) – <p>When running under Oracle VPN, the connection to the OCIGenAI service requires to run the model without any proxy.
Therefore, make sure not to have any of <code class="docutils literal notranslate"><span class="pre">http_proxy</span></code> or <code class="docutils literal notranslate"><span class="pre">HTTP_PROXY</span></code> environment variables setup,
or unset them with <code class="docutils literal notranslate"><span class="pre">unset</span> <span class="pre">http_proxy</span> <span class="pre">HTTP_PROXY</span></code>. Please also ensure that the <code class="docutils literal notranslate"><span class="pre">OPENAI_API_KEY</span></code> is set beforehand
to access this model. A list of available OpenAI models can be found at the following
link: <a class="reference external" href="https://platform.openai.com/docs/models">OpenAI Models</a></p>
</p></li>
<li><p><strong>__metadata_info__</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – </p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">wayflowcore.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">LlmModelFactory</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">OPENAI_CONFIG</span> <span class="o">=</span> <span class="p">{</span>
<span class="gp">... </span>    <span class="s2">&quot;model_type&quot;</span><span class="p">:</span> <span class="s2">&quot;openai&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">,</span>
<span class="gp">... </span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">llm</span> <span class="o">=</span> <span class="n">LlmModelFactory</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">OPENAI_CONFIG</span><span class="p">)</span>  
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>When running with Oracle VPN, you need to specify a https proxy, either globally or at the model level:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">OPENAI_CONFIG</span> <span class="o">=</span> <span class="p">{</span>
<span class="gp">... </span>   <span class="s2">&quot;model_type&quot;</span><span class="p">:</span> <span class="s2">&quot;openai&quot;</span><span class="p">,</span>
<span class="gp">... </span>   <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">,</span>
<span class="gp">... </span>   <span class="s2">&quot;proxy&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;PROXY_ADDRESS&gt;&quot;</span><span class="p">,</span>
<span class="gp">... </span><span class="p">}</span>  
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="wayflowcore.models.openaimodel.OpenAIModel.config">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">config</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#wayflowcore.models.openaimodel.OpenAIModel.config" title="Permalink to this definition">#</a></dt>
<dd><p>Get the configuration dictionary for the {VLlm/OpenAI/…} model</p>
</dd></dl>

</dd></dl>

</section>
<section id="ollama-models">
<h3>Ollama Models<a class="headerlink" href="#ollama-models" title="Permalink to this heading">#</a></h3>
<span class="target" id="ollamamodel"></span><dl class="py class">
<dt class="sig sig-object py" id="wayflowcore.models.ollamamodel.OllamaModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wayflowcore.models.ollamamodel.</span></span><span class="sig-name descname"><span class="pre">OllamaModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">host_port</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'localhost:11434'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proxy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generation_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">supports_structured_generation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">supports_tool_calling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">__metadata_info__</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">description</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.ollamamodel.OllamaModel" title="Permalink to this definition">#</a></dt>
<dd><p>Model powered by a locally hosted Ollama server.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_id</strong> (<em>str</em>) – Name of the model to use. List of model names can be found here:
<a class="reference external" href="https://ollama.com/search">https://ollama.com/search</a></p></li>
<li><p><strong>host_port</strong> (<em>str</em>) – Hostname and port of the vllm server where the model is hosted.
By default Ollama binds port 11434.</p></li>
<li><p><strong>proxy</strong> (<em>str</em><em> | </em><em>None</em>) – Proxy to use to connect to the remote LLM endpoint</p></li>
<li><p><strong>generation_config</strong> (<a class="reference internal" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig" title="wayflowcore.models.llmgenerationconfig.LlmGenerationConfig"><em>LlmGenerationConfig</em></a><em> | </em><em>None</em>) – default parameters for text generation with this model</p></li>
<li><p><strong>supports_structured_generation</strong> (<em>bool</em><em> | </em><em>None</em>) – Whether the model supports structured generation or not. When set to <cite>None</cite>,
the model will be prompted with a response format and it will check it can use
structured generation.</p></li>
<li><p><strong>supports_tool_calling</strong> (<em>bool</em><em> | </em><em>None</em>) – Whether the model supports tool calling or not. When set to <cite>None</cite>,
the model will be prompted with a tool and it will check it can use
the tool.</p></li>
<li><p><strong>id</strong> (<em>str</em><em> | </em><em>None</em>) – ID of the component.</p></li>
<li><p><strong>name</strong> (<em>str</em><em> | </em><em>None</em>) – Name of the component.</p></li>
<li><p><strong>description</strong> (<em>str</em><em> | </em><em>None</em>) – Description of the component.</p></li>
<li><p><strong>__metadata_info__</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – </p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">wayflowcore.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">LlmModelFactory</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">OLLAMA_CONFIG</span> <span class="o">=</span> <span class="p">{</span>
<span class="gp">... </span>    <span class="s2">&quot;model_type&quot;</span><span class="p">:</span> <span class="s2">&quot;ollama&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;MODEL_NAME&gt;&quot;</span><span class="p">,</span>
<span class="gp">... </span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">llm</span> <span class="o">=</span> <span class="n">LlmModelFactory</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">OLLAMA_CONFIG</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>As of November 2024, Ollama does not support tool calling with token streaming. To enable this functionality,
we prepend and append some specific REACT prompts and format tools with the REACT prompting template when:</p>
<ul class="simple">
<li><p>the model should use tools</p></li>
<li><p>the list of message contains some tool_requests or tool_results</p></li>
</ul>
<p>Be aware of that when you generate with tools or tool calls. To disable this behaviour, set <cite>use_tools</cite> to False
and make sure the prompt doesn’t contain tool_call and tool_result messages.
See <a class="reference external" href="https://arxiv.org/abs/2210.03629">https://arxiv.org/abs/2210.03629</a> for learning more about the REACT prompting techniques.</p>
<dl class="py property">
<dt class="sig sig-object py" id="wayflowcore.models.ollamamodel.OllamaModel.config">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">config</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#wayflowcore.models.ollamamodel.OllamaModel.config" title="Permalink to this definition">#</a></dt>
<dd><p>Get the configuration dictionary for the {VLlm/OpenAI/…} model</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="wayflowcore.models.ollamamodel.OllamaModel.default_agent_template">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">default_agent_template</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="prompttemplate.html#wayflowcore.templates.template.PromptTemplate" title="wayflowcore.templates.template.PromptTemplate"><span class="pre">PromptTemplate</span></a></em><a class="headerlink" href="#wayflowcore.models.ollamamodel.OllamaModel.default_agent_template" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="wayflowcore.models.ollamamodel.OllamaModel.default_chat_template">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">default_chat_template</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="prompttemplate.html#wayflowcore.templates.template.PromptTemplate" title="wayflowcore.templates.template.PromptTemplate"><span class="pre">PromptTemplate</span></a></em><a class="headerlink" href="#wayflowcore.models.ollamamodel.OllamaModel.default_chat_template" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="vllm-models">
<h3>VLLM Models<a class="headerlink" href="#vllm-models" title="Permalink to this heading">#</a></h3>
<span class="target" id="vllmmodel"></span><dl class="py class">
<dt class="sig sig-object py" id="wayflowcore.models.vllmmodel.VllmModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wayflowcore.models.vllmmodel.</span></span><span class="sig-name descname"><span class="pre">VllmModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">host_port</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proxy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generation_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">supports_structured_generation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">supports_tool_calling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">__metadata_info__</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">description</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.vllmmodel.VllmModel" title="Permalink to this definition">#</a></dt>
<dd><p>Model powered by a model hosted with VLLM server.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_id</strong> (<em>str</em>) – Name of the model to use</p></li>
<li><p><strong>host_port</strong> (<em>str</em>) – Hostname and port of the vllm server where the model is hosted</p></li>
<li><p><strong>proxy</strong> (<em>str</em><em> | </em><em>None</em>) – Proxy to use to connect to the remote LLM endpoint</p></li>
<li><p><strong>generation_config</strong> (<a class="reference internal" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig" title="wayflowcore.models.llmgenerationconfig.LlmGenerationConfig"><em>LlmGenerationConfig</em></a><em> | </em><em>None</em>) – default parameters for text generation with this model</p></li>
<li><p><strong>supports_structured_generation</strong> (<em>bool</em><em> | </em><em>None</em>) – Whether the model supports structured generation or not. When set to <cite>None</cite>,
the model will be prompted with a response format and it will check it can use
structured generation.</p></li>
<li><p><strong>supports_tool_calling</strong> (<em>bool</em><em> | </em><em>None</em>) – Whether the model supports tool calling or not. When set to <cite>None</cite>,
the model will be prompted with a tool and it will check it can use
the tool.</p></li>
<li><p><strong>id</strong> (<em>str</em><em> | </em><em>None</em>) – ID of the component.</p></li>
<li><p><strong>name</strong> (<em>str</em><em> | </em><em>None</em>) – Name of the component.</p></li>
<li><p><strong>description</strong> (<em>str</em><em> | </em><em>None</em>) – Description of the component.</p></li>
<li><p><strong>__metadata_info__</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – </p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">wayflowcore.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">LlmModelFactory</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">VLLM_CONFIG</span> <span class="o">=</span> <span class="p">{</span>
<span class="gp">... </span>    <span class="s2">&quot;model_type&quot;</span><span class="p">:</span> <span class="s2">&quot;vllm&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s2">&quot;host_port&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;HOSTNAME&gt;&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;MODEL_NAME&gt;&quot;</span><span class="p">,</span>
<span class="gp">... </span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">llm</span> <span class="o">=</span> <span class="n">LlmModelFactory</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">VLLM_CONFIG</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Usually, VLLM models do not support tool calling. To enable this, we prepend and append some specific REACT
prompts and format tools with the REACT prompting template when:</p>
<ul class="simple">
<li><p>the model should use tools</p></li>
<li><p>the list of message contains some tool_requests or tool_results</p></li>
</ul>
<p>Be aware of that when you generate with tools or tool calls. To disable this behaviour, set <cite>use_tools</cite> to False
and make sure the prompt doesn’t contain tool_call and tool_result messages.
See <a class="reference external" href="https://arxiv.org/abs/2210.03629">https://arxiv.org/abs/2210.03629</a> for learning more about the REACT prompting techniques.</p>
<p class="rubric">Notes</p>
<p>When running under Oracle VPN, the connection to the OCIGenAI service requires to run the model without any proxy.
Therefore, make sure not to have any of <cite>http_proxy</cite> or <cite>HTTP_PROXY</cite> environment variables setup, or unset them with <cite>unset http_proxy HTTP_PROXY</cite></p>
<dl class="py property">
<dt class="sig sig-object py" id="wayflowcore.models.vllmmodel.VllmModel.config">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">config</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#wayflowcore.models.vllmmodel.VllmModel.config" title="Permalink to this definition">#</a></dt>
<dd><p>Get the configuration dictionary for the {VLlm/OpenAI/…} model</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="wayflowcore.models.vllmmodel.VllmModel.default_agent_template">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">default_agent_template</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="prompttemplate.html#wayflowcore.templates.template.PromptTemplate" title="wayflowcore.templates.template.PromptTemplate"><span class="pre">PromptTemplate</span></a></em><a class="headerlink" href="#wayflowcore.models.vllmmodel.VllmModel.default_agent_template" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="wayflowcore.models.vllmmodel.VllmModel.default_chat_template">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">default_chat_template</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="prompttemplate.html#wayflowcore.templates.template.PromptTemplate" title="wayflowcore.templates.template.PromptTemplate"><span class="pre">PromptTemplate</span></a></em><a class="headerlink" href="#wayflowcore.models.vllmmodel.VllmModel.default_chat_template" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="oci-genai-models">
<h3>OCI GenAI Models<a class="headerlink" href="#oci-genai-models" title="Permalink to this heading">#</a></h3>
<span class="target" id="ocigenaimodel"></span><dl class="py class">
<dt class="sig sig-object py" id="wayflowcore.models.ocigenaimodel.OCIGenAIModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wayflowcore.models.ocigenaimodel.</span></span><span class="sig-name descname"><span class="pre">OCIGenAIModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compartment_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">client_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">serving_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">provider</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generation_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">description</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">__metadata_info__</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">service_endpoint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">auth_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">auth_profile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'DEFAULT'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.ocigenaimodel.OCIGenAIModel" title="Permalink to this definition">#</a></dt>
<dd><p>Model powered by OCIGenAI.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_id</strong> (<em>str</em>) – Name of the model to use.</p></li>
<li><p><strong>compartment_id</strong> (<em>str</em><em> | </em><em>None</em>) – The compartment OCID. Can be also configured in the <cite>OCI_GENAI_COMPARTMENT</cite> env variable.</p></li>
<li><p><strong>client_config</strong> (<em>OCIClientConfig</em><em> | </em><em>None</em>) – OCI client config to authenticate the OCI service.</p></li>
<li><p><strong>serving_mode</strong> (<em>ServingMode</em><em> | </em><em>None</em>) – OCI serving mode for the model. Either <code class="docutils literal notranslate"><span class="pre">ServingMode.ON_DEMAND</span></code> or <code class="docutils literal notranslate"><span class="pre">ServingMode.DEDICATED</span></code>.
When set to None, it will be auto-detected based on the <code class="docutils literal notranslate"><span class="pre">model_id</span></code>.</p></li>
<li><p><strong>provider</strong> (<em>ModelProvider</em><em> | </em><em>None</em>) – Name of the provider of the underlying model, to adapt the request.
Needs to be specified in <code class="docutils literal notranslate"><span class="pre">ServingMode.DEDICATED</span></code>. Is auto-detected when in <code class="docutils literal notranslate"><span class="pre">ServingMode.ON_DEMAND</span></code>
based on the <code class="docutils literal notranslate"><span class="pre">model_id</span></code>.</p></li>
<li><p><strong>generation_config</strong> (<a class="reference internal" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig" title="wayflowcore.models.llmgenerationconfig.LlmGenerationConfig"><em>LlmGenerationConfig</em></a><em> | </em><em>None</em>) – default parameters for text generation with this model</p></li>
<li><p><strong>id</strong> (<em>str</em><em> | </em><em>None</em>) – ID of the component.</p></li>
<li><p><strong>name</strong> (<em>str</em><em> | </em><em>None</em>) – Name of the component.</p></li>
<li><p><strong>description</strong> (<em>str</em><em> | </em><em>None</em>) – Description of the component.</p></li>
<li><p><strong>__metadata_info__</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – </p></li>
<li><p><strong>service_endpoint</strong> (<em>str</em><em> | </em><em>None</em>) – </p></li>
<li><p><strong>auth_type</strong> (<em>str</em><em> | </em><em>None</em>) – </p></li>
<li><p><strong>auth_profile</strong> (<em>str</em><em> | </em><em>None</em>) – </p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">wayflowcore.models.ocigenaimodel</span><span class="w"> </span><span class="kn">import</span> <span class="n">OCIGenAIModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">wayflowcore.models.ociclientconfig</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
<span class="gp">... </span>    <span class="n">OCIClientConfigWithInstancePrincipal</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">OCIClientConfigWithApiKey</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">## Example 1. Instance Principal</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">client_config</span> <span class="o">=</span> <span class="n">OCIClientConfigWithInstancePrincipal</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">service_endpoint</span><span class="o">=</span><span class="s2">&quot;my_service_endpoint&quot;</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">## Example 2. API Key from a config file (~/.oci/config)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">client_config</span> <span class="o">=</span> <span class="n">OCIClientConfigWithApiKey</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">service_endpoint</span><span class="o">=</span><span class="s2">&quot;my_service_endpoint&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">auth_profile</span><span class="o">=</span><span class="s2">&quot;DEFAULT&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">_auth_file_location</span><span class="o">=</span><span class="s2">&quot;~/.oci/config&quot;</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">llm</span> <span class="o">=</span> <span class="n">OCIGenAIModel</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;xai.grok-4&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">client_config</span><span class="o">=</span><span class="n">client_config</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">compartment_id</span><span class="o">=</span><span class="s2">&quot;my_compartment_id&quot;</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>  
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>When running under Oracle VPN, the connection to the OCIGenAI service requires to run the model without any proxy.
Therefore, make sure not to have any of <cite>http_proxy</cite> or <cite>HTTP_PROXY</cite> environment variables setup, or unset them with <cite>unset http_proxy HTTP_PROXY</cite></p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If when using <code class="docutils literal notranslate"><span class="pre">INSTANCE_PRINCIPAL</span></code> authentication, the response of the model returns a <code class="docutils literal notranslate"><span class="pre">404</span></code> error, please check if the machine is listed in the dynamic group and has the right privileges. Otherwise, please ask someone with administrative privileges.
To grant an OCI Compute instance the ability to authenticate as an Instance Principal, one needs to define a Dynamic Group that includes the instance and create a policy that allows this dynamic group to manage OCI GenAI services.</p>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="wayflowcore.models.ocigenaimodel.OCIGenAIModel.config">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">config</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#wayflowcore.models.ocigenaimodel.OCIGenAIModel.config" title="Permalink to this definition">#</a></dt>
<dd><p>Get the configuration dictionary for the {VLlm/OpenAI/…} model</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="wayflowcore.models.ocigenaimodel.OCIGenAIModel.default_agent_template">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">default_agent_template</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="prompttemplate.html#wayflowcore.templates.template.PromptTemplate" title="wayflowcore.templates.template.PromptTemplate"><span class="pre">PromptTemplate</span></a></em><a class="headerlink" href="#wayflowcore.models.ocigenaimodel.OCIGenAIModel.default_agent_template" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="wayflowcore.models.ocigenaimodel.OCIGenAIModel.default_chat_template">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">default_chat_template</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="prompttemplate.html#wayflowcore.templates.template.PromptTemplate" title="wayflowcore.templates.template.PromptTemplate"><span class="pre">PromptTemplate</span></a></em><a class="headerlink" href="#wayflowcore.models.ocigenaimodel.OCIGenAIModel.default_chat_template" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<section id="oci-client-config-classes-for-authentication">
<span id="ociclientconfigclassesforauthentication"></span><h4>OCI Client Config Classes for Authentication<a class="headerlink" href="#oci-client-config-classes-for-authentication" title="Permalink to this heading">#</a></h4>
<span class="target" id="ociclientconfigwithapikey"></span><dl class="py class">
<dt class="sig sig-object py" id="wayflowcore.models.ociclientconfig.OCIClientConfigWithApiKey">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wayflowcore.models.ociclientconfig.</span></span><span class="sig-name descname"><span class="pre">OCIClientConfigWithApiKey</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">service_endpoint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compartment_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">auth_profile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_auth_file_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.ociclientconfig.OCIClientConfigWithApiKey" title="Permalink to this definition">#</a></dt>
<dd><p>OCI client config class for authentication using API_KEY.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>service_endpoint</strong> (<em>str</em>) – the endpoint of the OCI GenAI service.</p></li>
<li><p><strong>compartment_id</strong> (<em>str</em><em> | </em><em>None</em>) – compartment id to use.</p></li>
<li><p><strong>auth_profile</strong> (<em>str</em><em> | </em><em>None</em>) – name of the profile to use in the config file. Defaults to “DEFAULT”.</p></li>
<li><p><strong>_auth_file_location</strong> (<em>str</em><em> | </em><em>None</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="wayflowcore.models.ociclientconfig.OCIClientConfigWithApiKey.to_dict">
<span class="sig-name descname"><span class="pre">to_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.ociclientconfig.OCIClientConfigWithApiKey.to_dict" title="Permalink to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Dict</em>[str, str | <em>Dict</em>[str, str]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<span class="target" id="ociclientconfigwithsecuritytoken"></span><dl class="py class">
<dt class="sig sig-object py" id="wayflowcore.models.ociclientconfig.OCIClientConfigWithSecurityToken">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wayflowcore.models.ociclientconfig.</span></span><span class="sig-name descname"><span class="pre">OCIClientConfigWithSecurityToken</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">service_endpoint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compartment_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">auth_profile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_auth_file_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.ociclientconfig.OCIClientConfigWithSecurityToken" title="Permalink to this definition">#</a></dt>
<dd><p>OCI client config class for authentication using SECURITY_TOKEN.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>service_endpoint</strong> (<em>str</em>) – the endpoint of the OCI GenAI service.</p></li>
<li><p><strong>compartment_id</strong> (<em>str</em><em> | </em><em>None</em>) – compartment id to use.</p></li>
<li><p><strong>auth_profile</strong> (<em>str</em><em> | </em><em>None</em>) – name of the profile to use in the config file. Defaults to “DEFAULT”.</p></li>
<li><p><strong>_auth_file_location</strong> (<em>str</em><em> | </em><em>None</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="wayflowcore.models.ociclientconfig.OCIClientConfigWithSecurityToken.to_dict">
<span class="sig-name descname"><span class="pre">to_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.ociclientconfig.OCIClientConfigWithSecurityToken.to_dict" title="Permalink to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Dict</em>[str, str | <em>Dict</em>[str, str]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<span class="target" id="ociclientconfigwithinstanceprincipal"></span><dl class="py class">
<dt class="sig sig-object py" id="wayflowcore.models.ociclientconfig.OCIClientConfigWithInstancePrincipal">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wayflowcore.models.ociclientconfig.</span></span><span class="sig-name descname"><span class="pre">OCIClientConfigWithInstancePrincipal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">service_endpoint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compartment_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.ociclientconfig.OCIClientConfigWithInstancePrincipal" title="Permalink to this definition">#</a></dt>
<dd><p>OCI client config class for authentication using INSTANCE_PRINCIPAL.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>service_endpoint</strong> (<em>str</em>) – the endpoint of the OCI GenAI service.</p></li>
<li><p><strong>compartment_id</strong> (<em>str</em><em> | </em><em>None</em>) – compartment id to use.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<span class="target" id="ociclientconfigwithresourceprincipal"></span><dl class="py class">
<dt class="sig sig-object py" id="wayflowcore.models.ociclientconfig.OCIClientConfigWithResourcePrincipal">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wayflowcore.models.ociclientconfig.</span></span><span class="sig-name descname"><span class="pre">OCIClientConfigWithResourcePrincipal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">service_endpoint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compartment_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.ociclientconfig.OCIClientConfigWithResourcePrincipal" title="Permalink to this definition">#</a></dt>
<dd><p>OCI client config class for authentication using RESOURCE_PRINCIPAL.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>service_endpoint</strong> (<em>str</em>) – the endpoint of the OCI GenAI service.</p></li>
<li><p><strong>compartment_id</strong> (<em>str</em><em> | </em><em>None</em>) – compartment id to use.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<span class="target" id="ociclientconfigwithuserauthentication"></span><dl class="py class">
<dt class="sig sig-object py" id="wayflowcore.models.ociclientconfig.OCIClientConfigWithUserAuthentication">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wayflowcore.models.ociclientconfig.</span></span><span class="sig-name descname"><span class="pre">OCIClientConfigWithUserAuthentication</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">service_endpoint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">user_config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compartment_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.ociclientconfig.OCIClientConfigWithUserAuthentication" title="Permalink to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>service_endpoint</strong> (<em>str</em>) – </p></li>
<li><p><strong>user_config</strong> (<a class="reference internal" href="#wayflowcore.models.ociclientconfig.OCIUserAuthenticationConfig" title="wayflowcore.models.ociclientconfig.OCIUserAuthenticationConfig"><em>OCIUserAuthenticationConfig</em></a>) – </p></li>
<li><p><strong>compartment_id</strong> (<em>str</em><em> | </em><em>None</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="wayflowcore.models.ociclientconfig.OCIClientConfigWithUserAuthentication.to_dict">
<span class="sig-name descname"><span class="pre">to_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.ociclientconfig.OCIClientConfigWithUserAuthentication.to_dict" title="Permalink to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Dict</em>[str, str | <em>Dict</em>[str, <em>Any</em>]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<div class="admonition important">
<p class="admonition-title">Important</p>
<p><code class="docutils literal notranslate"><span class="pre">OCIClientConfigWithUserAuthentication</span></code> supports the same authentication type as <code class="docutils literal notranslate"><span class="pre">OCIClientConfigWithApiKey</span></code> but without a config file.
Values in the config file are passed directly through <code class="docutils literal notranslate"><span class="pre">OCIUserAuthenticationConfig</span></code> below.</p>
</div>
<span class="target" id="ociuserauthenticationconfig"></span><dl class="py class">
<dt class="sig sig-object py" id="wayflowcore.models.ociclientconfig.OCIUserAuthenticationConfig">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">wayflowcore.models.ociclientconfig.</span></span><span class="sig-name descname"><span class="pre">OCIUserAuthenticationConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">user</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key_content</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fingerprint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tenancy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">region</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.ociclientconfig.OCIUserAuthenticationConfig" title="Permalink to this definition">#</a></dt>
<dd><p>Create an OCI user authentication config, which can be passed to the OCIClientConfigWithUserAuthentication class in order to authenticate the OCI service.</p>
<p>This class provides a way to authenticate the OCI service without relying on a config file.
In other words, it is equivalent to saving the config in a file and passing the file using OCIClientConfigWithApiKey class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>user</strong> (<em>str</em>) – user OCID</p></li>
<li><p><strong>key_content</strong> (<em>str</em>) – content of the private key</p></li>
<li><p><strong>fingerprint</strong> (<em>str</em>) – fingerprint of your public key</p></li>
<li><p><strong>tenancy</strong> (<em>str</em>) – tenancy OCID</p></li>
<li><p><strong>region</strong> (<em>str</em>) – OCI region</p></li>
<li><p><strong>warning::</strong> (<em>..</em>) – This class contains sensitive information. Please make sure that the contents are not printed or logged.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="wayflowcore.models.ociclientconfig.OCIUserAuthenticationConfig.from_dict">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">client_config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.ociclientconfig.OCIUserAuthenticationConfig.from_dict" title="Permalink to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>client_config</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>str</em><em>]</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#wayflowcore.models.ociclientconfig.OCIUserAuthenticationConfig" title="wayflowcore.models.ociclientconfig.OCIUserAuthenticationConfig"><em>OCIUserAuthenticationConfig</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="wayflowcore.models.ociclientconfig.OCIUserAuthenticationConfig.to_dict">
<span class="sig-name descname"><span class="pre">to_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#wayflowcore.models.ociclientconfig.OCIUserAuthenticationConfig.to_dict" title="Permalink to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Dict</em>[str, str]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The serialization of this class is currently not supported since the values are sensitive information.</p>
</div>
</section>
</section>
</section>
</section>


                </article>
              
              
              
              
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#llmmodel">LlmModel</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmmodel.LlmModel"><code class="docutils literal notranslate"><span class="pre">LlmModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmmodel.LlmModel.config"><code class="docutils literal notranslate"><span class="pre">LlmModel.config</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmmodel.LlmModel.default_agent_template"><code class="docutils literal notranslate"><span class="pre">LlmModel.default_agent_template</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmmodel.LlmModel.default_chat_template"><code class="docutils literal notranslate"><span class="pre">LlmModel.default_chat_template</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmmodel.LlmModel.generate"><code class="docutils literal notranslate"><span class="pre">LlmModel.generate()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmmodel.LlmModel.generate_async"><code class="docutils literal notranslate"><span class="pre">LlmModel.generate_async()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmmodel.LlmModel.get_total_token_consumption"><code class="docutils literal notranslate"><span class="pre">LlmModel.get_total_token_consumption()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmmodel.LlmModel.stream_generate"><code class="docutils literal notranslate"><span class="pre">LlmModel.stream_generate()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmmodel.LlmModel.stream_generate_async"><code class="docutils literal notranslate"><span class="pre">LlmModel.stream_generate_async()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#llmmodelfactory">LlmModelFactory</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmmodelfactory.LlmModelFactory"><code class="docutils literal notranslate"><span class="pre">LlmModelFactory</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmmodelfactory.LlmModelFactory.from_config"><code class="docutils literal notranslate"><span class="pre">LlmModelFactory.from_config()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#token-usage">Token Usage</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.tokenusage.TokenUsage"><code class="docutils literal notranslate"><span class="pre">TokenUsage</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.tokenusage.TokenUsage.cached_tokens"><code class="docutils literal notranslate"><span class="pre">TokenUsage.cached_tokens</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.tokenusage.TokenUsage.exact_count"><code class="docutils literal notranslate"><span class="pre">TokenUsage.exact_count</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.tokenusage.TokenUsage.input_tokens"><code class="docutils literal notranslate"><span class="pre">TokenUsage.input_tokens</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.tokenusage.TokenUsage.output_tokens"><code class="docutils literal notranslate"><span class="pre">TokenUsage.output_tokens</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.tokenusage.TokenUsage.total_tokens"><code class="docutils literal notranslate"><span class="pre">TokenUsage.total_tokens</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#llm-generation-config">LLM Generation Config</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig"><code class="docutils literal notranslate"><span class="pre">LlmGenerationConfig</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.extra_args"><code class="docutils literal notranslate"><span class="pre">LlmGenerationConfig.extra_args</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.frequency_penalty"><code class="docutils literal notranslate"><span class="pre">LlmGenerationConfig.frequency_penalty</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.from_dict"><code class="docutils literal notranslate"><span class="pre">LlmGenerationConfig.from_dict()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.max_tokens"><code class="docutils literal notranslate"><span class="pre">LlmGenerationConfig.max_tokens</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.merge_config"><code class="docutils literal notranslate"><span class="pre">LlmGenerationConfig.merge_config()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.stop"><code class="docutils literal notranslate"><span class="pre">LlmGenerationConfig.stop</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.temperature"><code class="docutils literal notranslate"><span class="pre">LlmGenerationConfig.temperature</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.to_dict"><code class="docutils literal notranslate"><span class="pre">LlmGenerationConfig.to_dict()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.llmgenerationconfig.LlmGenerationConfig.top_p"><code class="docutils literal notranslate"><span class="pre">LlmGenerationConfig.top_p</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#all-models">All models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#openai-compatible-models">OpenAI Compatible Models</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.openaicompatiblemodel.OpenAICompatibleModel"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.openaicompatiblemodel.OpenAICompatibleModel.config"><code class="docutils literal notranslate"><span class="pre">OpenAICompatibleModel.config</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#openai-models">OpenAI Models</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.openaimodel.OpenAIModel"><code class="docutils literal notranslate"><span class="pre">OpenAIModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.openaimodel.OpenAIModel.config"><code class="docutils literal notranslate"><span class="pre">OpenAIModel.config</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ollama-models">Ollama Models</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.ollamamodel.OllamaModel"><code class="docutils literal notranslate"><span class="pre">OllamaModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.ollamamodel.OllamaModel.config"><code class="docutils literal notranslate"><span class="pre">OllamaModel.config</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.ollamamodel.OllamaModel.default_agent_template"><code class="docutils literal notranslate"><span class="pre">OllamaModel.default_agent_template</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.ollamamodel.OllamaModel.default_chat_template"><code class="docutils literal notranslate"><span class="pre">OllamaModel.default_chat_template</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vllm-models">VLLM Models</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.vllmmodel.VllmModel"><code class="docutils literal notranslate"><span class="pre">VllmModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.vllmmodel.VllmModel.config"><code class="docutils literal notranslate"><span class="pre">VllmModel.config</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.vllmmodel.VllmModel.default_agent_template"><code class="docutils literal notranslate"><span class="pre">VllmModel.default_agent_template</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.vllmmodel.VllmModel.default_chat_template"><code class="docutils literal notranslate"><span class="pre">VllmModel.default_chat_template</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#oci-genai-models">OCI GenAI Models</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.ocigenaimodel.OCIGenAIModel"><code class="docutils literal notranslate"><span class="pre">OCIGenAIModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.ocigenaimodel.OCIGenAIModel.config"><code class="docutils literal notranslate"><span class="pre">OCIGenAIModel.config</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.ocigenaimodel.OCIGenAIModel.default_agent_template"><code class="docutils literal notranslate"><span class="pre">OCIGenAIModel.default_agent_template</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.ocigenaimodel.OCIGenAIModel.default_chat_template"><code class="docutils literal notranslate"><span class="pre">OCIGenAIModel.default_chat_template</span></code></a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#oci-client-config-classes-for-authentication">OCI Client Config Classes for Authentication</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.ociclientconfig.OCIClientConfigWithApiKey"><code class="docutils literal notranslate"><span class="pre">OCIClientConfigWithApiKey</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h6 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.ociclientconfig.OCIClientConfigWithApiKey.to_dict"><code class="docutils literal notranslate"><span class="pre">OCIClientConfigWithApiKey.to_dict()</span></code></a></li>
</ul>
</li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.ociclientconfig.OCIClientConfigWithSecurityToken"><code class="docutils literal notranslate"><span class="pre">OCIClientConfigWithSecurityToken</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h6 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.ociclientconfig.OCIClientConfigWithSecurityToken.to_dict"><code class="docutils literal notranslate"><span class="pre">OCIClientConfigWithSecurityToken.to_dict()</span></code></a></li>
</ul>
</li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.ociclientconfig.OCIClientConfigWithInstancePrincipal"><code class="docutils literal notranslate"><span class="pre">OCIClientConfigWithInstancePrincipal</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.ociclientconfig.OCIClientConfigWithResourcePrincipal"><code class="docutils literal notranslate"><span class="pre">OCIClientConfigWithResourcePrincipal</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.ociclientconfig.OCIClientConfigWithUserAuthentication"><code class="docutils literal notranslate"><span class="pre">OCIClientConfigWithUserAuthentication</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h6 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.ociclientconfig.OCIClientConfigWithUserAuthentication.to_dict"><code class="docutils literal notranslate"><span class="pre">OCIClientConfigWithUserAuthentication.to_dict()</span></code></a></li>
</ul>
</li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.ociclientconfig.OCIUserAuthenticationConfig"><code class="docutils literal notranslate"><span class="pre">OCIUserAuthenticationConfig</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h6 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.ociclientconfig.OCIUserAuthenticationConfig.from_dict"><code class="docutils literal notranslate"><span class="pre">OCIUserAuthenticationConfig.from_dict()</span></code></a></li>
<li class="toc-h6 nav-item toc-entry"><a class="reference internal nav-link" href="#wayflowcore.models.ociclientconfig.OCIUserAuthenticationConfig.to_dict"><code class="docutils literal notranslate"><span class="pre">OCIUserAuthenticationConfig.to_dict()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=dba54f56160742ef5599"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=dba54f56160742ef5599"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2025, Oracle and/or its affiliates..
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 6.1.0.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>